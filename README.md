# CARP-S
Welcome to CARP-S! 
This repository contains a benchmarking framework for optimizers.
It allows flexibly combining optimizers and benchmarks via a simple interface, and logging experiment results 
and trajectories to a database.

The main topics of this README are:
- [Installation](#installation)
- [Minimal Example](#minimal-example)
- [Commands](#commands)
- [Adding a new Optimizer or Benchmark](#adding-a-new-optimizer-or-benchmark)

For more details on CARP-S, please have a look at the 
[documentation](https://AutoML.github.io/CARP-S/latest/).

## Installation
To install CARP-S, you can use the following commands:

```bash
git clone https://github.com/AutoML/CARP-S.git
cd CARP-S
conda create -n carps python=3.11
conda activate carps

# Install for usage
pip install .
```

If you want to install CARP-S for development, you can use the following command:
```bash
# Install for development
make install-dev
```

Additionally, you need to install the requirements for the benchmark and optimizer that you want to use.
For example, if you want to use the `SMAC2.0` optimizer and the `BBOB` benchmark, you need to install the
requirements for both of them.

```bash
pip install -r container_recipes/optimizers/SMAC3/SMAC3_requirements.txt
pip install -r container_recipes/benchmarks/BBOB/BBOB_requirements.txt
```

## Minimal Example
Once the requirements for both an optimizer and a benchmark, e.g. `SMAC2.0` and `BBOB`, are installed, you can run
one of the following minimal examples to benchmark `SMAC2.0` on `BBOB` directly with Hydra:

```bash
# Run SMAC BlackBoxFacade on certain BBOB problem
python -m carps.run +optimizer/smac20=blackbox +problem/BBOB=cfg_4_1_4_0 seed=1 task.n_trials=25

# Run SMAC BlackBoxFacade on all available BBOB problems for 10 seeds
python -m carps.run +optimizer/smac20=blackbox '+problem/BBOB=glob(*)' 'seed=range(1,11)' -m
```

For the second command, the Hydra -m (or --multirun) option indicates that multiple runs will be 
performed over a range of parameter values. In this case, it's indicating that the benchmarking
should be run for all available BBOB problems (+problem/BBOB=glob(*)) and for 10 different 
seed values (seed=range(1,11)).

## Commands

You can run a certain problem and optimizer combination directly with Hydra via:
```bash
python -m carps.run +problem=... +optimizer=... seed=... -m
```

Another option is to fill the database with all possible combinations of problems and optimizers
you would like to run:
```bash
python -m carps.container.create_cluster_configs +problem=... +optimizer=... -m
```

Then, run them from the database with:
```bash
python -m carps.run_from_db 
```

To check whether any runs are missing, you can use the following command. It will create
a file `runcommands_missing.sh` containing the missing runs:
```bash
python -m carps.utils.check_missing <rundir>
```

To collect all run data generated by the file logger into csv files, use the following command:
```bash
python -m carps.analysis.gather_data <rundir>
```
The csv files are then located in `<rundir>`. `logs.csv` contain the trial info and values and 
`logs_cfg.csv` contain the experiment  configuration.
The experiments can be matched via the column `experiment_id`.

Experiments with error status (or any other status) can be reset via:
```bash
python -m carps.utils.database.reset_experiments
```

## Adding a new Optimizer or Benchmark
For instructions on how to add a new optimizer or benchmark, please refer to the contributing 
guidelines for 
[benchmarks](https://automl.github.io/CARP-S/latest/contributing/contributing-a-benchmark/)
and
[optimizers](https://automl.github.io/CARP-S/latest/contributing/contributing-an-optimizer/).
