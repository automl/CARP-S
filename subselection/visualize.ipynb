{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset tasks\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "\n",
    "subset_config_dir = Path(\"../carps/configs/task/subselection\")\n",
    "subset_config_fns = list(subset_config_dir.glob(\"**/*.yaml\"))\n",
    "\n",
    "keys = [\"task_type\", \"subset_id\", \"task_id\"]\n",
    "\n",
    "def read_task_config(config_fn: Path) -> dict:\n",
    "    config = OmegaConf.load(config_fn)\n",
    "    return {k: config.get(k) for k in keys}\n",
    "\n",
    "with Pool() as pool:\n",
    "    task_infos = pool.map(read_task_config, subset_config_fns)\n",
    "\n",
    "task_df = pd.DataFrame(task_infos)\n",
    "task_df[\"benchmark_id\"] = task_df[\"task_id\"].apply(lambda x: x.split(\"/\")[3].lower())\n",
    "task_df.to_csv(\"subset_tasks.csv\", index=False)\n",
    "task_df[\"task_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_subset_configs import fix_legacy_task_id\n",
    "\n",
    "paths = [\n",
    "    \"../subselection/data/BBv2_lognorm/df_crit.csv\",\n",
    "    \"../subselection/data/MOv2_norm/df_crit.csv\",\n",
    "    \"../subselection/data_subselection/MOMF/lognorm/df_crit.csv\",\n",
    "    \"../subselection/data_subselection/MF/lognorm/df_crit.csv\"\n",
    "]\n",
    "task_types = [\n",
    "    \"blackbox\",\n",
    "    \"multi-objective\",\n",
    "    \"multi-fidelity-objective\",\n",
    "    \"multi-fidelity\"\n",
    "]\n",
    "source_df_list = []\n",
    "for task_type, path in zip(task_types, paths):\n",
    "    df = pd.read_csv(path)  # noqa: PD901\n",
    "    df[\"task_type\"] = task_type\n",
    "    df = df.rename(columns={\"problem_id\": \"task_id\"})\n",
    "    df[\"task_id\"] = df[\"task_id\"].apply(fix_legacy_task_id)\n",
    "    df[\"benchmark_id\"] = df[\"task_id\"].apply(lambda x: x.split(\"/\")[0].lower())\n",
    "    source_df_list.append(df)\n",
    "source_df = pd.concat(source_df_list)\n",
    "source_df.to_csv(\"source_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from carps.analysis.utils import setup_seaborn, savefig\n",
    "\n",
    "setup_seaborn()\n",
    "\n",
    "source_df = pd.read_csv(\"source_df.csv\")\n",
    "task_df = pd.read_csv(\"subset_tasks.csv\")\n",
    "\n",
    "id_columns = [\"task_type\", \"task_id\", \"subset_id\", \"benchmark_id\"]\n",
    "optimizer_columns = [c for c in source_df.columns if c not in id_columns]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3*4,2))\n",
    "axes = fig.subplots(1, 4)\n",
    "\n",
    "task_types = task_df[\"task_type\"].unique()\n",
    "\n",
    "for i, task_type in enumerate(task_types):\n",
    "    task_subset_df = task_df[task_df[\"task_type\"] == task_type]\n",
    "    source_subset_df = source_df[source_df[\"task_type\"] == task_type]\n",
    "    source_subset_df = source_subset_df.dropna(axis=1, how=\"any\")\n",
    "    optimizer_columns_sub = [c for c in optimizer_columns if c in source_subset_df.columns]\n",
    "    performance_tensor_source = source_subset_df[optimizer_columns_sub].to_numpy()\n",
    "    print(performance_tensor_source.shape)\n",
    "\n",
    "    original_task_ids = task_subset_df[\"task_id\"].apply(\n",
    "            lambda x: \"/\".join(x.split(\"/\")[3:]) if x else x)\n",
    "    task_subset_df[\"original_task_id\"] = original_task_ids\n",
    "\n",
    "    source_subset_task_df = source_subset_df[\n",
    "        source_subset_df[\"task_id\"].isin(task_subset_df[\"original_task_id\"])\n",
    "    ]\n",
    "    source_subset_task_df.loc[:, \"subset_id\"] = source_subset_df[\"task_id\"].apply(\n",
    "        lambda x: task_subset_df[\"subset_id\"][task_subset_df[\"original_task_id\"] == x].to_numpy())\n",
    "    source_subset_task_df.loc[:, \"subset_id\"] = source_subset_task_df.loc[:, \"subset_id\"].apply(lambda x: x[0])\n",
    "    performance_tensor_subset = source_subset_task_df[optimizer_columns_sub].to_numpy()\n",
    "    print(performance_tensor_subset.shape)\n",
    "\n",
    "\n",
    "\n",
    "    def get_2d_tensor(tsne, tensor_3d: np.ndarray) -> np.ndarray:\n",
    "        # tsne = TSNE(n_components=2, random_state=42, perplexity=10)\n",
    "        # tsne.fit(tensor_3d)\n",
    "        # return tsne.fit_transform(tensor_3d)\n",
    "        return tsne.transform(tensor_3d)\n",
    "    np.random.seed(42)\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    # tsne.fit(performance_tensor_source)\n",
    "    tsne = PCA(n_components=2)\n",
    "    tsne.fit(performance_tensor_source)\n",
    "\n",
    "    tensor_2d_source = get_2d_tensor(tsne, performance_tensor_source)\n",
    "    tensor_2d_subset_dev = get_2d_tensor(tsne,\n",
    "        source_subset_task_df[source_subset_task_df[\"subset_id\"] == \"dev\"][optimizer_columns_sub].to_numpy()\n",
    "    )\n",
    "    tensor_2d_subset_test = get_2d_tensor(tsne,\n",
    "        source_subset_task_df[source_subset_task_df[\"subset_id\"] == \"test\"][optimizer_columns_sub].to_numpy()\n",
    "    )\n",
    "\n",
    "    plot_df = pd.concat([\n",
    "        pd.DataFrame({\n",
    "            \"x0\": tensor_2d_source[:, 0],\n",
    "            \"x1\": tensor_2d_source[:, 1],\n",
    "            \"subset_id\": \"Source\"\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            \"x0\": tensor_2d_subset_dev[:, 0],\n",
    "            \"x1\": tensor_2d_subset_dev[:, 1],\n",
    "            \"subset_id\": \"Dev\"\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            \"x0\": tensor_2d_subset_test[:, 0],\n",
    "            \"x1\": tensor_2d_subset_test[:, 1],\n",
    "            \"subset_id\": \"Test\"\n",
    "        })\n",
    "    ])\n",
    "\n",
    "    # Plot the 2D representation of the data\n",
    "    marker_shapes = {\"Source\": \"o\", \"Dev\": \"*\", \"Test\": \"p\"}\n",
    "    marker_sizes = {\"Source\": 60*1.25, \"Dev\": 50*1.25, \"Test\": 40*1.25}\n",
    "    color_palette = {\"Source\": \"grey\", \"Dev\": \"mediumvioletred\", \"Test\": \"forestgreen\"}\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax = sns.scatterplot(\n",
    "        data=plot_df, x=\"x0\", y=\"x1\", hue=\"subset_id\", ax=ax,\n",
    "        style=\"subset_id\",  # This will use different shapes for each hue\n",
    "        markers=marker_shapes,  # Custom shapes for each hue\n",
    "        size=\"subset_id\",  # This will adjust the size based on the hue\n",
    "        sizes=marker_sizes,  # Custom sizes for each hue\n",
    "        linewidth=0.2,\n",
    "        palette=color_palette,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{task_type}\")\n",
    "\n",
    "\n",
    "    if i != len(task_types) - 1:\n",
    "        ax.get_legend().remove()\n",
    "    else:\n",
    "        ax.legend(title=\"Subset\", loc=\"upper right\", bbox_to_anchor=(1.75, 1.0))\n",
    "fig.set_tight_layout(True)\n",
    "# fig.suptitle(rf\"PCA (3d $\\rightarrow$ 2d)\")\n",
    "savefig(fig, \"subset_pca\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from carps.analysis.utils import setup_seaborn, savefig\n",
    "from omegaconf import DictConfig\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "setup_seaborn()\n",
    "\n",
    "source_df = pd.read_csv(\"source_df.csv\")\n",
    "task_df = pd.read_csv(\"subset_tasks.csv\")\n",
    "\n",
    "id_columns = [\"task_type\", \"task_id\", \"subset_id\", \"benchmark_id\"]\n",
    "optimizer_columns = [c for c in source_df.columns if c not in id_columns]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3*4,2*3))\n",
    "axes = fig.subplots(3, 4)\n",
    "\n",
    "task_types = task_df[\"task_type\"].unique()\n",
    "\n",
    "for i, task_type in enumerate(task_types):\n",
    "    task_subset_df = task_df[task_df[\"task_type\"] == task_type]\n",
    "\n",
    "    source_subset_df = source_df[source_df[\"task_type\"] == task_type]\n",
    "    source_subset_df = source_subset_df.dropna(axis=1, how=\"any\")\n",
    "    optimizer_columns_sub = [c for c in optimizer_columns if c in source_subset_df.columns]\n",
    "    performance_tensor_source = source_subset_df[optimizer_columns_sub].to_numpy()\n",
    "    print(performance_tensor_source.shape)\n",
    "\n",
    "    original_task_ids = task_subset_df[\"task_id\"].apply(\n",
    "            lambda x: \"/\".join(x.split(\"/\")[3:]) if x else x)\n",
    "    task_subset_df[\"original_task_id\"] = original_task_ids\n",
    "\n",
    "    source_subset_task_df = source_subset_df[\n",
    "        source_subset_df[\"task_id\"].isin(task_subset_df[\"original_task_id\"])\n",
    "    ]\n",
    "    source_subset_task_df.loc[:, \"subset_id\"] = source_subset_df[\"task_id\"].apply(\n",
    "        lambda x: task_subset_df[\"subset_id\"][task_subset_df[\"original_task_id\"] == x].to_numpy())\n",
    "    source_subset_task_df.loc[:, \"subset_id\"] = source_subset_task_df.loc[:, \"subset_id\"].apply(lambda x: x[0])\n",
    "    performance_tensor_subset = source_subset_task_df[optimizer_columns_sub].to_numpy()\n",
    "    print(performance_tensor_subset.shape)\n",
    "\n",
    "\n",
    "\n",
    "    def get_2d_tensor(tsne, tensor_3d: np.ndarray) -> np.ndarray:\n",
    "        # tsne = TSNE(n_components=2, random_state=42, perplexity=10)\n",
    "        # tsne.fit(tensor_3d)\n",
    "        # return tsne.fit_transform(tensor_3d)\n",
    "        return tsne.transform(tensor_3d)\n",
    "    np.random.seed(42)\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    # tsne.fit(performance_tensor_source)\n",
    "    tsne = PCA(n_components=2)\n",
    "    tsne.fit(performance_tensor_source)\n",
    "\n",
    "    tensor_2d_source = get_2d_tensor(tsne, performance_tensor_source)\n",
    "    tensor_2d_subset_dev = get_2d_tensor(tsne,\n",
    "        source_subset_task_df[source_subset_task_df[\"subset_id\"] == \"dev\"][optimizer_columns_sub].to_numpy()\n",
    "    )\n",
    "    tensor_2d_subset_test = get_2d_tensor(tsne,\n",
    "        source_subset_task_df[source_subset_task_df[\"subset_id\"] == \"test\"][optimizer_columns_sub].to_numpy()\n",
    "    )\n",
    "\n",
    "    plot_df = pd.concat([\n",
    "        pd.DataFrame({\n",
    "            \"x0\": tensor_2d_source[:, 0],\n",
    "            \"x1\": tensor_2d_source[:, 1],\n",
    "            \"subset_id\": \"Source\"\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            \"x0\": tensor_2d_subset_dev[:, 0],\n",
    "            \"x1\": tensor_2d_subset_dev[:, 1],\n",
    "            \"subset_id\": \"Dev\"\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            \"x0\": tensor_2d_subset_test[:, 0],\n",
    "            \"x1\": tensor_2d_subset_test[:, 1],\n",
    "            \"subset_id\": \"Test\"\n",
    "        })\n",
    "    ])\n",
    "\n",
    "\n",
    "    # SCATTERPLOT\n",
    "    # Plot the 2D representation of the data\n",
    "    marker_shapes = {\"Source\": \"o\", \"Dev\": \"*\", \"Test\": \"p\"}\n",
    "    marker_sizes = {\"Source\": 60*1.25, \"Dev\": 50*1.25, \"Test\": 40*1.25}\n",
    "    color_palette = {\"Source\": \"grey\", \"Dev\": \"mediumvioletred\", \"Test\": \"forestgreen\"}\n",
    "    ax = axes[0,i]\n",
    "    ax = sns.scatterplot(\n",
    "        data=plot_df, x=\"x0\", y=\"x1\", hue=\"subset_id\", ax=ax,\n",
    "        style=\"subset_id\",  # This will use different shapes for each hue\n",
    "        markers=marker_shapes,  # Custom shapes for each hue\n",
    "        size=\"subset_id\",  # This will adjust the size based on the hue\n",
    "        sizes=marker_sizes,  # Custom sizes for each hue\n",
    "        linewidth=0.2,\n",
    "        palette=color_palette,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    n_source = len(tensor_2d_source)\n",
    "    n_dev = len(tensor_2d_subset_dev)\n",
    "    n_test = len(tensor_2d_subset_test)\n",
    "    ax.set_title(f\"{task_type}\\n(Source: {n_source}, Dev: {n_dev}, Test: {n_test})\")\n",
    "    if i != len(task_types) - 1:\n",
    "        ax.get_legend().remove()\n",
    "    else:\n",
    "        ax.legend(title=\"Subset\", loc=\"upper right\", bbox_to_anchor=(1.75, 1.0))\n",
    "\n",
    "\n",
    "    custom_legend = [\n",
    "        Line2D([0], [0], marker=\"s\", color=\"w\", markerfacecolor=\"mediumvioletred\", markersize=10, label=\"Dev\"),\n",
    "        Line2D([0], [0], marker=\"s\", color=\"w\", markerfacecolor=\"forestgreen\", markersize=10, label=\"Test\")\n",
    "    ]\n",
    "\n",
    "    # HISTOGRAM BENCHMARK FAMILIES\n",
    "    renamer = {\"source\": \"Source\", \"dev\": \"Dev\", \"test\": \"Test\"}\n",
    "    task_subset_df[\"subset_id\"] = task_subset_df[\"subset_id\"].map(renamer)\n",
    "    print(task_subset_df.columns)\n",
    "    print(task_subset_df[\"benchmark_id\"].count())\n",
    "    ax = axes[1,i]\n",
    "    ax = sns.histplot(data=task_subset_df, x=\"benchmark_id\", hue=\"subset_id\",\n",
    "        multiple=\"dodge\", shrink=0.8, ax=ax, palette=color_palette, discrete=True)\n",
    "    if i != len(task_types) - 1:\n",
    "        ax.get_legend().remove()\n",
    "    else:\n",
    "        ax.legend(handles=custom_legend, title=\"Subset\", loc=\"upper right\", bbox_to_anchor=(1.65, 1.0))\n",
    "    \n",
    "    # HISTOGRAM DIMENSIONS\n",
    "    ax = axes[2,i]\n",
    "    def get_dim(task_id: str) -> int:\n",
    "        index_fn = Path(\"../carps/configs/task/index.csv\")\n",
    "        if not index_fn.is_file():\n",
    "            raise ValueError(\"ObjectiveFunction ids have not been indexed. Run `python -m carps.utils.index_configs`.\")\n",
    "        task_index = pd.read_csv(index_fn)\n",
    "\n",
    "        def load_task_cfg(task_id: str) -> DictConfig:\n",
    "            subset = task_index[\"config_fn\"][task_index[\"task_id\"] == task_id]\n",
    "            if len(subset) == 0:\n",
    "                raise ValueError(\n",
    "                    f\"Can't find config_fn for {task_id}. Maybe the index is old. Run \"\n",
    "                    \"`python -m carps.utils.index_configs` to refresh.\"\n",
    "                )\n",
    "            config_fn = subset.iloc[0]\n",
    "            if not Path(config_fn).is_file():\n",
    "                raise ValueError(\n",
    "                    f\"Can't find config_fn for {task_id}. Maybe the index is old. Run \"\n",
    "                    \"`python -m carps.utils.index_configs` to refresh.\"\n",
    "                )\n",
    "            cfg = OmegaConf.load(config_fn)\n",
    "            return cfg.task\n",
    "        task = load_task_cfg(task_id)\n",
    "        dimension = task.metadata.dimensions\n",
    "        return dimension\n",
    "    \n",
    "    dimensions_df = pd.DataFrame([\n",
    "        {\"dimension\": get_dim(row[\"task_id\"]), \"subset_id\": row[\"subset_id\"]} for _, row in task_subset_df.iterrows()])\n",
    "    ax = sns.histplot(data=dimensions_df, x=\"dimension\", hue=\"subset_id\",\n",
    "        multiple=\"dodge\", shrink=0.8, ax=ax, palette=color_palette, discrete=False, bins=10)\n",
    "    if i != len(task_types) - 1:\n",
    "        ax.get_legend().remove()\n",
    "    else:\n",
    "        ax.legend(handles=custom_legend, title=\"Subset\", loc=\"upper right\", bbox_to_anchor=(1.65, 1.0))\n",
    "    \n",
    "fig.set_tight_layout(True)\n",
    "# fig.suptitle(rf\"PCA (3d $\\rightarrow$ 2d)\")\n",
    "savefig(fig, \"subset_stats\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carpsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
